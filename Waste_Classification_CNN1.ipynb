{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6396f0-12e2-4fc0-84fb-1c3ff276329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Environment check\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db7a65f3-2368-494e-ab64-faa1b353a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30ad384c-65f8-4f83-9e66-0ffd3dbdf07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Dataset path & params\n",
    "dataset_path = r\"C:\\Users\\srina\\Downloads\\archive\\garbage-dataset\"   # update if needed\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ffcb9-fce8-4640-b943-60c23c688e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load dataset (80% train, 20% val)\n",
    "train_ds = image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "val_ds = image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Classes found:\", class_names)\n",
    "num_classes = len(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3cc3384-6225-4e91-a394-ce33f1541af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Performance (optional but recommended)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a142bb6c-47a5-4213-8c11-7e4a9f52648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Build model\n",
    "model = models.Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(224, 224, 3)),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18cc98-1ba7-4942-a19a-619c69315196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Train model\n",
    "EPOCHS = 10   # change to 20/30 if you want\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4226e20-b060-4e3f-a855-8842871eb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Plot metrics\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6665e0-1828-4709-ab4b-b658cb780fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9A. Test single image using in-memory model (no reload needed)\n",
    "img_path = r\"C:\\Users\\srina\\Downloads\\archive\\garbage-dataset\\plastic\\plastic_93.jpg\"\n",
    "img = image.load_img(img_path, target_size=img_size)\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "prediction = model.predict(img_array)     # using the model in memory\n",
    "predicted_class = class_names[np.argmax(prediction)]\n",
    "confidence = round(np.max(prediction) * 100, 2)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Confidence:\", confidence, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c38295-c9f3-43d7-be77-f714fc50a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9B. If you restarted the kernel or opened new session: load model first\n",
    "model_loaded = keras.models.load_model(\"waste_classifier_model.keras\")\n",
    "print(\"Loaded model:\", model_loaded)\n",
    "\n",
    "img_path = r\"C:\\Users\\srina\\Downloads\\archive\\garbage-dataset\\plastic\\plastic_93.jpg\"\n",
    "img = image.load_img(img_path, target_size=img_size)\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "prediction = model_loaded.predict(img_array)\n",
    "predicted_class = class_names[np.argmax(prediction)]\n",
    "confidence = round(np.max(prediction) * 100, 2)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Confidence:\", confidence, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2266893-e0d0-4bad-8ea1-fc94929d2153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Save model (saves a separate file in working directory)\n",
    "model.save(\"waste_classifier_model.keras\")\n",
    "print(\"Model saved to waste_classifier_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c2a97f-efd9-43e3-b9d3-6ea33fba65ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
